{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pPzsKphiQnpx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676717748404,"user_tz":-330,"elapsed":35439,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"bb773798-30ab-4da1-dfa7-b2d33f3b2c8d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2218,"status":"ok","timestamp":1676627216027,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"},"user_tz":-330},"id":"Y3OfyHOy4y3z","outputId":"e02dc13b-dc20-4d76-b3ae-05b27ca3f3bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 10.7M  100 10.7M    0     0  11.0M      0 --:--:-- --:--:-- --:--:-- 11.0M\n"]}],"source":["!curl -L https://raw.githubusercontent.com/PacktPublishing/Transformers-for-Natural-Language-Processing/master/Chapter03/kant.txt --output \"kant.txt\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44950,"status":"ok","timestamp":1676717863500,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"},"user_tz":-330},"id":"J9_6emwm2pOi","outputId":"35e11199-5f2c-4aee-fed6-f486d5e1baeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.11.0\n","Uninstalling tensorflow-2.11.0:\n","  Successfully uninstalled tensorflow-2.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-yoznbl6v\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-yoznbl6v\n","  Resolved https://github.com/huggingface/transformers to commit 7f1cdf18958efef6339040ba91edb32ae7377720\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (23.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (4.0.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6553472 sha256=ed6a9e8ea48f2166f4fe11fdcf40dde20e91fd173b392de2eead3ddd21790326\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r5hzay96/wheels/42/68/45/c63edff61c292f2dfd4df4ef6522dcbecc603e7af82813c1d7\n","Successfully built transformers\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.27.0.dev0\n","tokenizers                    0.13.2\n","transformers                  4.27.0.dev0\n"]}],"source":["!pip uninstall -y tensorflow\n","# Install `transformers` from master\n","!pip install git+https://github.com/huggingface/transformers\n","!pip list | grep -E 'transformers|tokenizers'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12584,"status":"ok","timestamp":1676627886274,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"},"user_tz":-330},"id":"KY9PW3MM4Mwh","outputId":"29e58d94-949b-4a64-a153-9b145afb6657"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 13.9 s, sys: 1.48 s, total: 15.4 s\n","Wall time: 11.8 s\n"]}],"source":["%%time \n","from pathlib import Path\n","\n","from tokenizers import ByteLevelBPETokenizer\n","\n","paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n","# Initialize a tokenizer\n","tokenizer = ByteLevelBPETokenizer()\n","\n","# Customize training\n","tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n","    \"<s>\",\n","    \"<pad>\",\n","    \"</s>\",\n","    \"<unk>\",\n","    \"<mask>\",\n","])"]},{"cell_type":"code","source":["import os\n","token_dir = '/content/drive/MyDrive/KantaiBERT'\n","if not os.path.exists(token_dir):\n","  os.makedirs(token_dir)\n","tokenizer.save_model('/content/drive/MyDrive/KantaiBERT')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g00U5qlzPmBO","executionInfo":{"status":"ok","timestamp":1676628218733,"user_tz":-330,"elapsed":1765,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"5da475cd-02c3-4a9a-c029-9243915976f0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/KantaiBERT/vocab.json',\n"," '/content/drive/MyDrive/KantaiBERT/merges.txt']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from tokenizers.implementations import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","\n","tokenizer = ByteLevelBPETokenizer(\n","    \"/content/drive/MyDrive/KantaiBERT/vocab.json\",\n","    \"/content/drive/MyDrive/KantaiBERT/merges.txt\",\n",")"],"metadata":{"id":"Qe3AY7RXQDpS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.encode(\"The Critique of Pure Reason.\").tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rjNjrJxRjOz","executionInfo":{"status":"ok","timestamp":1676628326019,"user_tz":-330,"elapsed":1056,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"83cd1505-7f03-4f5a-c493-fc5169d06569"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The', 'ĠCritique', 'Ġof', 'ĠPure', 'ĠReason', '.']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["tokenizer.encode(\"The Critique of Pure Reason.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2k8s3QH7RvuB","executionInfo":{"status":"ok","timestamp":1676628329311,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"ad4f3add-ef81-4eba-af89-5e27815c87cd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Encoding(num_tokens=6, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["tokenizer._tokenizer.post_processor = BertProcessing(\n","    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",")\n","tokenizer.enable_truncation(max_length=512)"],"metadata":{"id":"CnI3EGEARzsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auwuoKuxS-dv","executionInfo":{"status":"ok","timestamp":1676628567381,"user_tz":-330,"elapsed":871,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"86f372fb-3103-4af5-9a78-a9ed5e7c5512"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Feb 17 10:09:24 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"br-meoOmSAKv","executionInfo":{"status":"ok","timestamp":1676628591226,"user_tz":-330,"elapsed":2939,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"d11fdf42-4c64-45b4-bb6b-381bc650df80"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from transformers import RobertaConfig\n","\n","config = RobertaConfig(\n","    vocab_size=52_000,\n","    max_position_embeddings=514,\n","    num_attention_heads=12,\n","    num_hidden_layers=6,\n","    type_vocab_size=1,\n",")"],"metadata":{"id":"0W0awl-MS9_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsKyvIxUTEjI","executionInfo":{"status":"ok","timestamp":1676629012063,"user_tz":-330,"elapsed":590,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"f7acb140-c040-48f1-8a1f-e4842be0ec39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RobertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.27.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 52000\n","}\n","\n"]}]},{"cell_type":"code","source":["from transformers import RobertaTokenizer\n","tokenizer = RobertaTokenizer.from_pretrained(\"/content/drive/MyDrive/KantaiBERT\", max_length=512)"],"metadata":{"id":"WMCQXKruTGSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import RobertaForMaskedLM\n","\n","model = RobertaForMaskedLM(config=config)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IphbA0e4pva","executionInfo":{"status":"ok","timestamp":1676629262412,"user_tz":-330,"elapsed":4589,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"9f525b47-6f64-4c1f-8cfb-d0d43a4b2f2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RobertaForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=52000, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["print(model.num_parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qE2upy6g5CkB","executionInfo":{"status":"ok","timestamp":1676629328181,"user_tz":-330,"elapsed":879,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"169e98fb-d3b4-4b62-f5ff-a59a1bcc902e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["83504416\n"]}]},{"cell_type":"code","source":["LP=list(model.parameters())\n","lp=len(LP)\n","print(lp)\n","for p in range(0,lp):\n","  print(LP[p])"],"metadata":{"id":"27Cr2GJV5Tm4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","from transformers import LineByLineTextDataset\n","\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"/content/drive/MyDrive/KantaiBERT/kant.txt\",\n","    block_size=128,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TP-F0ndi9J54","executionInfo":{"status":"ok","timestamp":1676631279085,"user_tz":-330,"elapsed":32181,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"0ca13efd-7932-48e0-de5a-639b89aaef2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 30.6 s, sys: 395 ms, total: 31 s\n","Wall time: 32.1 s\n"]}]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")"],"metadata":{"id":"HqXzi24pA5IA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/KantaiBERT\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    per_device_train_batch_size=64,\n","    save_steps=10_000,\n","    save_total_limit=2,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YS_ywI-ZEK64","executionInfo":{"status":"ok","timestamp":1676635061623,"user_tz":-330,"elapsed":581,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"f9b164af-5eed-4134-a2aa-6ba33e0317d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["%%time\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6rfU6BdLFPZr","executionInfo":{"status":"ok","timestamp":1676640797277,"user_tz":-330,"elapsed":5733381,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"2de91a24-d45c-4722-ecc9-7ad09d63e393"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 170964\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 26720\n","  Number of trainable parameters = 83504416\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='26720' max='26720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [26720/26720 1:35:32, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.301400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.217400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.126300</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.104800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.110000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.110400</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>3.097100</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.045700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>3.053500</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.041100</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>3.009200</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>2.973100</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>2.983400</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>2.958600</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>2.948800</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>2.964200</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>2.899900</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>2.854200</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>2.847800</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>2.816100</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>2.766700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>2.738400</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>2.724600</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>2.664000</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>2.675800</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>2.646200</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>2.627800</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>2.558300</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>2.545800</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>2.536400</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>2.518500</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>2.518000</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>2.433300</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>2.428000</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>2.414900</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>2.396600</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>2.409500</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>2.378400</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>2.336200</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>2.351200</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>2.334500</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>2.304600</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>2.282000</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>2.280500</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>2.270000</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>2.264400</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>2.243600</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>2.239200</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>2.216600</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>2.225100</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>2.201300</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>2.205100</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>2.212600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/KantaiBERT/checkpoint-10000\n","Configuration saved in /content/drive/MyDrive/KantaiBERT/checkpoint-10000/config.json\n","Model weights saved in /content/drive/MyDrive/KantaiBERT/checkpoint-10000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/MyDrive/KantaiBERT/checkpoint-20000\n","Configuration saved in /content/drive/MyDrive/KantaiBERT/checkpoint-20000/config.json\n","Model weights saved in /content/drive/MyDrive/KantaiBERT/checkpoint-20000/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 1h 34min 7s, sys: 22.3 s, total: 1h 34min 30s\n","Wall time: 1h 35min 32s\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=26720, training_loss=2.645664129428521, metrics={'train_runtime': 5732.7498, 'train_samples_per_second': 298.223, 'train_steps_per_second': 4.661, 'total_flos': 8734366268749056.0, 'train_loss': 2.645664129428521, 'epoch': 10.0})"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["trainer.save_model(\"/content/drive/MyDrive/KantaiBERT\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2uC_rbLFQoX","executionInfo":{"status":"ok","timestamp":1676640798976,"user_tz":-330,"elapsed":1755,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"f44617e6-6d42-48b1-94e2-ac603f0783c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/KantaiBERT\n","Configuration saved in /content/drive/MyDrive/KantaiBERT/config.json\n","Model weights saved in /content/drive/MyDrive/KantaiBERT/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","fill_mask = pipeline(\n","    \"fill-mask\",\n","    model=\"/content/drive/MyDrive/KantaiBERT\",\n","    tokenizer=\"/content/drive/MyDrive/KantaiBERT\"\n",")"],"metadata":{"id":"PzL9vjY7GuVJ","executionInfo":{"status":"ok","timestamp":1676717986828,"user_tz":-330,"elapsed":15733,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["fill_mask(\"Human thinking involves human <mask>.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIq3QXpPLiqa","executionInfo":{"status":"ok","timestamp":1676718015534,"user_tz":-330,"elapsed":631,"user":{"displayName":"Ayush Shetty","userId":"02142876128819433052"}},"outputId":"3b043628-e5b2-4da1-fc60-8245b13b71ed"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.6369929313659668,\n","  'token': 393,\n","  'token_str': ' reason',\n","  'sequence': 'Human thinking involves human reason.'},\n"," {'score': 0.05386006459593773,\n","  'token': 989,\n","  'token_str': ' mind',\n","  'sequence': 'Human thinking involves human mind.'},\n"," {'score': 0.053131766617298126,\n","  'token': 588,\n","  'token_str': ' nature',\n","  'sequence': 'Human thinking involves human nature.'},\n"," {'score': 0.050371043384075165,\n","  'token': 486,\n","  'token_str': ' will',\n","  'sequence': 'Human thinking involves human will.'},\n"," {'score': 0.028977246955037117,\n","  'token': 815,\n","  'token_str': ' thought',\n","  'sequence': 'Human thinking involves human thought.'}]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"ddfxoEpwLnww"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}